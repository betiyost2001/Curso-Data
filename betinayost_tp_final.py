# -*- coding: utf-8 -*-
"""BetinaYost_transformaciones.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1V1gIvv-OPfoUv512j1D9BmXeDJy7SyBF

# Trabajo Final Integrador ‚Äì Yost Betina

Este trabajo cumple con los objetivos del curso de Ingenier√≠a de Datos:
- Extracci√≥n de datos desde una API
- Almacenamiento en formato Delta Lake (capa Bronze)
- Procesamiento y transformaci√≥n (Silver)
- Agregaci√≥n y an√°lisis (Gold)

---

## Parte 1: Extracci√≥n y almacenamiento (Bronze)
"""

# Instalamos dependencias necesarias
import os
import requests
import pandas as pd
from deltalake.writer import write_deltalake
from datetime import datetime

# Crear base del data lake
base_dir = "/content/datalake_tp1"
os.makedirs(base_dir, exist_ok=True)

# ======================
# DATOS DIN√ÅMICOS (pron√≥stico horario actual)
# ======================

# Par√°metros para C√≥rdoba, Argentina
url_dynamic = (
    "https://api.open-meteo.com/v1/forecast?latitude=-31.42&longitude=-64.19&hourly=temperature_2m,relative_humidity_2m,wind_speed_10m"
)

# ----------------------------------------
# PARTE 1 ‚Äì EXTRACCI√ìN Y ALMACENAMIENTO BRONZE
# ----------------------------------------

response_dynamic = requests.get(url_dynamic)
data_dynamic = response_dynamic.json()

# Extraer datos horarios
hourly_data = data_dynamic['hourly']
df_dynamic = pd.DataFrame(hourly_data)

# Agregar columnas para particionar
now = datetime.utcnow()
df_dynamic["date"] = now.strftime("%Y-%m-%d")
df_dynamic["hour"] = now.strftime("%H")

# Guardar en Delta Lake particionado
path_dynamic = os.path.join(base_dir, "clima_cordoba1")
write_deltalake(
    path_dynamic,
    df_dynamic,
    mode="append",
    partition_by=["date", "hour"]
)


# ======================
# 2. DATOS EST√ÅTICOS (informaci√≥n geogr√°fica de C√≥rdoba)
# ======================

url_static = "https://geocoding-api.open-meteo.com/v1/search?name=cordoba&count=1"
response_static = requests.get(url_static)
data_static = response_static.json()

df_static = pd.json_normalize(data_static['results'])

# Guardar en Delta Lake sin particionar (full)
path_static = os.path.join(base_dir, "ubicacion_cordoba")
write_deltalake(
    path_static,
    df_static,
    mode="overwrite"
)

# Mostrar rutas de almacenamiento
(path_dynamic, path_static)

"""# PARTE 2 ‚Äì PROCESAMIENTO Y TRANSFORMACI√ìN (SILVER)"""

# === PARTE 2 ‚Äì PROCESAMIENTO Y TRANSFORMACI√ìN (SILVER) ===
from deltalake import DeltaTable

bronze_path_dynamic = "/content/datalake_tp1/clima_cordoba1"
bronze_path_static = "/content/datalake_tp1/ubicacion_cordoba"

df_dynamic = DeltaTable(bronze_path_dynamic).to_pandas()
df_static = DeltaTable(bronze_path_static).to_pandas()

# Verificar columnas reales
print(df_dynamic.columns)
print(df_static.columns)

def limpiar_datos(df):
    # 1. Eliminar duplicados
    df = df.drop_duplicates()

    # 2. Reemplazar nulos por 0 en columnas relevantes
    df = df.fillna({
        "temperature_2m": 0,
        "relative_humidity_2m": 0,
        "wind_speed_10m": 0
    })

    # 3. Crear columna booleana: ¬øtemperatura alta (> 30¬∞C)?
    df["alta_temp"] = df["temperature_2m"] > 30

    return df

# ‚úÖ Llamar a la funci√≥n (afuera)
df_dynamic = limpiar_datos(df_dynamic)

#Procesamiento de datos est√°ticos

# 1. Eliminar duplicados
df_static = df_static.drop_duplicates()

# 2. Reemplazar nulos (ejemplo: poblaci√≥n vac√≠a la pasamos a 0)
df_static = df_static.fillna({
    "population": 0
})

# 3. Crear columna: ¬øzona densamente poblada?
df_static["alta_poblacion"] = df_static["population"] > 100000

# 4. Convertir a min√∫sculas los nombres para estandarizar
df_static["name"] = df_static["name"].str.lower()
df_static["country"] = df_static["country"].str.lower()

# Convertimos la fecha a datetime
df_dynamic["time"] = pd.to_datetime(df_dynamic["time"])

# Agregamos una columna solo con la fecha
df_dynamic["fecha"] = df_dynamic["time"].dt.date

# Agrupamos por fecha y sacamos estad√≠sticas
df_resumen = df_dynamic.groupby("fecha")[["temperature_2m", "relative_humidity_2m"]].agg(["mean", "max", "min"]).reset_index()

# Guardamos los datos procesados en la capa Silver (formato Delta)
from deltalake.writer import write_deltalake

write_deltalake("silver/clima", df_dynamic, mode="overwrite")
write_deltalake("silver/ubicacion", df_static, mode="overwrite")

# Calculamos estad√≠sticas agregadas (Gold) y las guardamos
write_deltalake("gold/resumen", df_resumen, mode="overwrite")

"""## Comentarios finales ‚Äì Trabajo Final Integrador

üîπ **Extracci√≥n de datos desde API p√∫blica (Open-Meteo)**:  
Se utilizaron dos endpoints distintos:  
- Un endpoint din√°mico con pron√≥stico horario de temperatura, humedad y viento (extracci√≥n incremental, particionado por fecha y hora).  
- Un endpoint est√°tico con informaci√≥n geogr√°fica de la ciudad (extracci√≥n full).  

üîπ **Almacenamiento en formato Delta Lake**:  
Los datos se almacenan seg√∫n las buenas pr√°cticas de un Data Lake, separados por capas:
- `bronze/` para datos crudos  
- `silver/` para datos transformados  
- `gold/` para datos agregados

üîπ **Transformaciones y limpieza de datos**:  
Se aplicaron al menos 4 transformaciones por dataset, incluyendo:
- Eliminaci√≥n de duplicados  
- Relleno de valores nulos  
- Conversi√≥n de fechas  
- Creaci√≥n de nuevas columnas (e.g., `alta_temp`)  
- Estandarizaci√≥n de texto  

üîπ **Agregaciones**:  
Se realiz√≥ un agrupamiento por fecha y se calcularon estad√≠sticas como promedio, m√°ximo y m√≠nimo de variables meteorol√≥gicas, guardadas en la capa `gold/`.

üîπ **Seguridad y confidencialidad**:  
Este proyecto **no utiliza credenciales ni informaci√≥n personal sensible (PII)**.  

No se manejan claves de acceso ni tokens de autenticaci√≥n.  
Se trabaj√≥ exclusivamente con datos p√∫blicos sin requerimientos de anonimizaci√≥n.

üîπ **Estructura y funciones**:  
El c√≥digo se encuentra organizado en secciones claramente delimitadas (Bronze, Silver, Gold).  
Adem√°s, las tareas repetitivas de limpieza fueron encapsuladas en funciones para mejorar la modularidad y reutilizaci√≥n.

---

**Betina Yost**  
Trabajo Final Integrador ‚Äì Ingenier√≠a de Datos  
UTN BA - Centro de eLearning

"""